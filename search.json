[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MIMIS Workshop 2024",
    "section": "",
    "text": "Este taller analiza las dificultades para estimar efectos causales en ciencias sociales y se introducen estrategias para abordar la causalidad mediante diseños experimentales y cuasi-experimentales.\nRequisitos: conocimientos básicos de test de hipótesis, regresión lineal y programación en R.\nTendremos tres sesiones:\nSesión 1: Problema fundamental de la inferencia causal y repaso de regresión lineal.\nLunes 04/11 de 18:00 – 20:30 hrs\nSesión 2: Diseños experimentales: aleatorización, diseño de bloques y cálculos de poder.\nLunes 11/11 de 18:00 – 20:30 hrs\nSesión 3: Técnicas con datos observacionales: matching y variables instrumentales. Lunes 18/11 de 18:00 – 20:30 hrs"
  },
  {
    "objectID": "index.html#aproximaciones-a-la-inferencia-causal-en-ciencias-sociales",
    "href": "index.html#aproximaciones-a-la-inferencia-causal-en-ciencias-sociales",
    "title": "MIMIS Workshop 2024",
    "section": "",
    "text": "Este taller analiza las dificultades para estimar efectos causales en ciencias sociales y se introducen estrategias para abordar la causalidad mediante diseños experimentales y cuasi-experimentales.\nRequisitos: conocimientos básicos de test de hipótesis, regresión lineal y programación en R.\nTendremos tres sesiones:\nSesión 1: Problema fundamental de la inferencia causal y repaso de regresión lineal.\nLunes 04/11 de 18:00 – 20:30 hrs\nSesión 2: Diseños experimentales: aleatorización, diseño de bloques y cálculos de poder.\nLunes 11/11 de 18:00 – 20:30 hrs\nSesión 3: Técnicas con datos observacionales: matching y variables instrumentales. Lunes 18/11 de 18:00 – 20:30 hrs"
  },
  {
    "objectID": "index.html#referencias",
    "href": "index.html#referencias",
    "title": "MIMIS Workshop 2024",
    "section": "Referencias",
    "text": "Referencias\nAngrist, J. D. y J. Pischke (2015). Mastering ’Metrics: The Path from Cause to Effect. Princeton University Press.\nCunningham, S. (2021). Causal inference. In Causal Inference. Yale University Press. Versión en inglés: https://mixtape.scunning.com/\nGerber, A. S. y D. P. Green (2012). Field Experiments: Design, Analysis, and Interpretation. New York: W. W. Norton.\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman and Hall/CRC. Versión en inglés: https://theeffectbook.net/index.html\nPearl, J., & Mackenzie, D. (2018). The book of why: the new science of cause and effect. Basic books. Lo puede encontrar aquí.\nStock, J. and Watson, M., Introduction to Econometrics, 3rd edition. (Disponible en Biblioteca SJ-UC)."
  },
  {
    "objectID": "index.html#links-complementarios",
    "href": "index.html#links-complementarios",
    "title": "MIMIS Workshop 2024",
    "section": "Links Complementarios",
    "text": "Links Complementarios\n\nR para Ciencia de Datos: Libro base para el uso de R, aquí podrán ver que la plataforma de Rstudio no es solo para el análisis estadístico, sino que de procesamiento de datos y reporte (versión en español).\nAnalizaR Datos Políticos: Manual con herramientas y tips prácticos para analizar datos políticos.\nUCLA: Espacio para aprender estadística y programación.\nCausal Inference in R: Libro que utiliza una combinación de ejemplos de la medicina, la economía y la tecnología para demostrar que se necesita una pregunta causal clara y la voluntad de ser transparente sobre las suposiciones."
  },
  {
    "objectID": "index.html#comunidades-y-foros",
    "href": "index.html#comunidades-y-foros",
    "title": "MIMIS Workshop 2024",
    "section": "Comunidades y foros",
    "text": "Comunidades y foros\nPara los que alguna vez fuimos nuevos en RStudio sirve bastante ver las preguntas/respuestas de otras personas en las comunidades de R (¡son muy activas!). De hecho, casi todas nuestras preguntas ya fueron respondidas por personas en todo el mundo. No olvidar que la mayoría de estos foros están en inglés:\n\nRStudio Community\nStackoverflow"
  },
  {
    "objectID": "index.html#otros-enlaces-de-interés",
    "href": "index.html#otros-enlaces-de-interés",
    "title": "MIMIS Workshop 2024",
    "section": "Otros enlaces de interés",
    "text": "Otros enlaces de interés\n\nCompendio de links útiles\nConectarse a Github desde R"
  },
  {
    "objectID": "S2.html",
    "href": "S2.html",
    "title": "Sesión 2: Diseños experimentales",
    "section": "",
    "text": "Considere una población de \\(i\\) unidades potencialmente expuestas a un tratamiento (causa) o control. La variable \\(D_i\\) nos indicará si la unidad \\(i\\) fue tratada (\\(D_i=t\\)) o no tratada, o sea control, (\\(D_i=c\\)).\nNos interesa evaluar el efecto sobre una variable de respuesta observada que denotaremos como \\(Y_i\\) con dos respuestas potenciales:\n\n\\(Y_i(t)\\) si la unidad fue tratada\n\\(Y_i(c)\\) en caso contrario\n\nDado que \\(Y_i\\) mide el efecto de la causa, entonces, los valores de \\(Y_i\\) son posteriores a la exposición del tratamiento.\nA su vez, denotamos que el modelo causal del tratamiento en una unidad \\(i\\) puede ser expresado como:\n\\[\\delta_i=Y_i(t)-Y_i(c)\\]\nLo interesante del modelo Neyman-Rubin es que el valor de \\(D_i\\) para cada unidad \\(i\\) podría haber sido distinto. Este es el problema.\n\\[Y_i=D_iY_i(t)-(1-D_i)Y_i(c)\\] Donde \\(D_i=1\\) si la persona fue tratada y \\(D_i=0\\) en caso contrario, entonces:\n\\[\\delta_i=(1)Y_i(t)-(1-0)Y_i(c)=Y_i(t)-Y_i(c)\\]\n\n\n\n\n\n\nProblema fundamental de la inferencia causal\n\n\n\nLa imposibilidad de observar una variable de respuesta \\(Y_i\\) en la misma unidad y al mismo tiempo para dos condiciones diferentes: \\(Y_i(t)\\) y \\(Y_i(c)\\) (Holland, 1986).\n\n\nSupuestos:\n\nIndependencia: \\((Y_{i}(t), Y_{i}(c)) \\perp D_{i}\\)\nRestricción de exclusión: \\(Y_{i}(1,d) = Y_{i}(0,d)\\)\nStable-unit-treatment assumption (SUTVA): no hay spillovers"
  },
  {
    "objectID": "S2.html#modelo-de-resultados-potenciales-neyman-rubin",
    "href": "S2.html#modelo-de-resultados-potenciales-neyman-rubin",
    "title": "Sesión 2: Diseños experimentales",
    "section": "",
    "text": "Considere una población de \\(i\\) unidades potencialmente expuestas a un tratamiento (causa) o control. La variable \\(D_i\\) nos indicará si la unidad \\(i\\) fue tratada (\\(D_i=t\\)) o no tratada, o sea control, (\\(D_i=c\\)).\nNos interesa evaluar el efecto sobre una variable de respuesta observada que denotaremos como \\(Y_i\\) con dos respuestas potenciales:\n\n\\(Y_i(t)\\) si la unidad fue tratada\n\\(Y_i(c)\\) en caso contrario\n\nDado que \\(Y_i\\) mide el efecto de la causa, entonces, los valores de \\(Y_i\\) son posteriores a la exposición del tratamiento.\nA su vez, denotamos que el modelo causal del tratamiento en una unidad \\(i\\) puede ser expresado como:\n\\[\\delta_i=Y_i(t)-Y_i(c)\\]\nLo interesante del modelo Neyman-Rubin es que el valor de \\(D_i\\) para cada unidad \\(i\\) podría haber sido distinto. Este es el problema.\n\\[Y_i=D_iY_i(t)-(1-D_i)Y_i(c)\\] Donde \\(D_i=1\\) si la persona fue tratada y \\(D_i=0\\) en caso contrario, entonces:\n\\[\\delta_i=(1)Y_i(t)-(1-0)Y_i(c)=Y_i(t)-Y_i(c)\\]\n\n\n\n\n\n\nProblema fundamental de la inferencia causal\n\n\n\nLa imposibilidad de observar una variable de respuesta \\(Y_i\\) en la misma unidad y al mismo tiempo para dos condiciones diferentes: \\(Y_i(t)\\) y \\(Y_i(c)\\) (Holland, 1986).\n\n\nSupuestos:\n\nIndependencia: \\((Y_{i}(t), Y_{i}(c)) \\perp D_{i}\\)\nRestricción de exclusión: \\(Y_{i}(1,d) = Y_{i}(0,d)\\)\nStable-unit-treatment assumption (SUTVA): no hay spillovers"
  },
  {
    "objectID": "S2.html#sesgo-de-selección",
    "href": "S2.html#sesgo-de-selección",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Sesgo de selección",
    "text": "Sesgo de selección\nTenemos tres tipos de efectos causales:\n\nEfecto causal promedio (ATE): es la diferencia como si (what-if) en el SIMCE que esperariamos si pudieramos educar de un modo aleatorio a estudiantes tanto en escuelas municipales y en escuelas privadas.\n\n\\[ATE = E[\\tau_i]=E[Y_i^1-Y_i^0]=E[Y_i^1]-E[Y_i^0]\\]\n\nEfecto causal del tratamiento para los tratados (ATT): es la diferencia como si (what-if) en el SIMCE que esperariamos si pudieramos educar de un modo aleatorio a estudiantes de colegios municipales tanto en escuelas municipales y en escuelas privadas.\n\n\\[ATT=E[\\tau_i|D_i=1]=E[Y_i^1-Y_i^0|D_i=1]=E[Y_i^1|D_i=1]-E[Y_i^0|D_i=1]\\]\n\nEfecto causal del tratamiento para los controles (ATU): es la diferencia como si (what-if) en el SIMCE que esperariamos si pudieramos educar de un modo aleatorio a estudiantes de colegios privados tanto en escuelas municipales y en escuelas privadas.\n\n\\[ATU=E[\\tau_i|D_i=1]=E[Y_i^1-Y_i^0|D_i=1]=E[Y_i^1|D_i=1]-E[Y_i^0|D_i=1]\\] Veamos un ejemplo:\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{split}ATE & = \\frac{1}{10}\\cdot(6-1+4-1+2 \\\\& \\quad +9-9-1-4+1) \\\\ & = \\frac{6}{10}=0.6\\end{split}\\]\n\\[\\begin{split}ATT & = \\frac{1}{5}\\cdot(6+4+2+9+1) \\\\ & = \\frac{22}{5}=4.4\\end{split}\\]\n\\[\\begin{split}ATU & = \\frac{1}{5}\\cdot(-1-1-9-1-4) \\\\ & = \\frac{-16}{5}=-3.2\\end{split}\\] Lo que está en naranjo no es observable, por lo que no es posible calcular el ATE directamente, entonces no es posible calcular ATE, ATT o ATU directamente, ya que los parámetros de interés no son observables.\n\n\n\n\n\n\nIdea clave\n\n\n\nLos distintos métodos de estimación de efectos causales persiguen siempre el mismo objetivo: usar información observable para construir un estimador plausible del contrafactual.\n\n\nPodríamos construir nuestras medidas a partir de un estimador de diferencia de medias (SDM) que utiliza la diferencia de promedios entre tratados y no tratados si es que se tiene una muestra aleatoria. Pero tenemos dos problemas:\n\\[\\begin{split}SDM & = E[Y_i|D_i=1]-E[Y_i|D_i=0] \\\\ \\\\ & = E[Y_i^1|D_i=1]-E[Y_i^0|D_i=0]\\color{orange}{+E[Y_i^0|D_i=1]-E[Y_i^0|D_i=1]} \\\\ \\\\ & = \\underset{ATT}{\\underbrace{E[Y_i^1-Y_i^0|D_i=1]}}+\\underset{\\text{Selection Bias}}{\\underbrace{\\big\\{E[Y_i^0|D_i=1]-E[Y_i^0|D_i=0]\\big\\}}}\\end{split}\\] Sea \\(\\pi=E[D_i]\\), entonces:\n\\[\\begin{split}ATE = E[\\tau_i] & = \\pi\\cdot E[\\tau_i|D_i=1]+(1-\\pi)\\cdot E[\\tau_i|D_i=0] \\\\ & = \\pi \\cdot ATT + (1-\\pi)\\cdot ATU \\color{orange}{+ ATT - ATT} \\\\ & = (1-\\pi)\\cdot (ATU-ATT) + ATT \\\\ \\Rightarrow ATT & = ATE+(1-\\pi) \\cdot (ATT-ATU) \\end{split}\\]\nEntonces:\n\\[SDM = ATE+\\underset{\\text{Heterogeneous Treatment Effect Bias}}{\\underbrace{(1-\\pi)\\cdot (ATT-ATU)}}+\\underset{\\text{Selection Bias}}{\\underbrace{\\big\\{E[Y_i^0|D_i=1]-E[Y_i^0|D_i=0]\\big\\}}}\\] - Para que el SDM identifique el \\(ATE\\), tenemos que .orange[suponer]:\\[E[Y_i^0|D_i]=E[Y_i^0] \\quad \\text{y} \\quad E[\\tau_i|D_i]=E[\\tau_i]\\] - Una condición suficiente es \\((Y_i^0,Y_i^1)\\perp D_i\\)\n¿Cuándo tenemos problemas?\n\nLas personas que reciben un tratamiento suelen ser quienes más lo necesitan \\(Y_i^0\\not\\perp D_i\\).\nLas personas que reciben un tratamiento suelen ser quienes mayores beneficios pueden obtener del tratamiento \\((Y_i^1-Y_i^0)\\not\\perp D_i\\)"
  },
  {
    "objectID": "S2.html#asignación-aleatoria",
    "href": "S2.html#asignación-aleatoria",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Asignación aleatoria",
    "text": "Asignación aleatoria\nLa asignación aleatoria es un procedimiento mediante el cual las unidades en un estudio se asignan al tratamiento de manera imparcial, como lanzar una moneda. Este proceso busca asegurar que la asignación sea independiente de las características de las unidades.\nLa asignación aleatoria asegura que todas las combinaciones posibles de asignación de tratamiento tienen la misma probabilidad de ocurrir.\n\\[Pr(Z | \\Omega) = \\frac{1}{\\Omega}, \\forall Z \\in \\Omega\\]\n\n\n\n\n\nSabemos que:\n\\[SDM = ATE+\\underset{\\text{Heterogeneous Treatment Effect Bias}}{\\underbrace{(1-\\pi)\\cdot (ATT-ATU)}}+\\underset{\\text{Selection Bias}}{\\underbrace{\\big\\{E[Y_i^0|D_i=1]-E[Y_i^0|D_i=0]\\big\\}}}\\]\n\nLa asignación aleatoria de un tratamiento garantiza que \\((Y_i^0,Y_i^1)\\perp D_i\\), con lo cual:\n\n\\(\\underset{ATT}{\\underbrace{E[Y_i^1-Y_i^0|D_i=1]}}=\\underset{ATU}{\\underbrace{E[Y_i^1-Y_i^0|D_i=0]}}=\\underset{ATE}{\\underbrace{E[Y_i^1-Y_i^0]}}\\)\n\\(E[Y_i^0|D_i=1]=E[Y_i^0|D_i=0]\\)\n\nPor lo tanto, si el tratamiento se asigna en forma aleatoria,\n\n\\[SDM = ATE = ATT = ATU\\]\nProcedimiento para Asignación Aleatoria Completa:\n\nDeterminar el número total de sujetos \\(N\\) y el tamaño del grupo de tratamiento \\(m\\).\nGenerar un número aleatorio para cada sujeto.\nOrdenar los sujetos de menor a mayor de acuerdo con el número aleatorio.\nAsignar los primeros \\(m\\) sujetos al grupo de tratamiento.\n\nOtros tipos de asignaciones: no restrigida, restringida (condicional).\nHagamos un ejercicio de simulación:\n\n\nClick para ver el código\nN=100000 #número de observaciones\nY0 &lt;- rnorm(n=N, mean=0, sd=1)# resultado potencial - C\nY1 &lt;- rnorm(n=N, mean=0.2, sd=1)# resultado potencial - T\n\n# Asignación aleatoria del tratamiento\nD=(rnorm(N)&gt;0)\n\n\nGrafiquemos las distribuciones:\n\n\nClick para ver el código\nlibrary(ggplot2)\nlibrary(ggpubr)\n\n# Crear data frames para cada distribución\ndata_Y0 &lt;- data.frame(Outcome = Y0, Group = ifelse(D, \"Treatment\", \"Control\"))\ndata_Y1 &lt;- data.frame(Outcome = Y1, Group = ifelse(D, \"Treatment\", \"Control\"))\n\n# Gráfico de densidad para Y0\nplot_Y0 &lt;- ggplot(data_Y0, aes(x = Outcome, fill = Group)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(aes(xintercept = mean(Outcome[Group == \"Treatment\"])), color = \"red\", linetype = \"dashed\") +\n  geom_vline(aes(xintercept = mean(Outcome[Group == \"Control\"])), color = \"blue\", linetype = \"dashed\") +\n  labs(title = expression(\"Distribución de \" ~ Y[0]), x = \"Outcome\", y = \"Density\") +\n  theme_minimal() +\n  theme(legend.position = \"top\")\n\n# Gráfico de densidad para Y1\nplot_Y1 &lt;- ggplot(data_Y1, aes(x = Outcome, fill = Group)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(aes(xintercept = mean(Outcome[Group == \"Treatment\"])), color = \"red\", linetype = \"dashed\") +\n  geom_vline(aes(xintercept = mean(Outcome[Group == \"Control\"])), color = \"blue\", linetype = \"dashed\") +\n  labs(title = expression(\"Distribución de \" ~ Y[1]), x = \"Outcome\", y = \"Density\") +\n  theme_minimal() +\n  theme(legend.position = \"top\")\n\n# Combinar los gráficos en una fila\nggpubr::ggarrange(plot_Y0, plot_Y1, nrow=1, common.legend = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nClick para ver el código\n#ATE:\nmean(Y1-Y0)\n\n\n[1] 0.2005293\n\n\nClick para ver el código\n#ATT:\nmean(Y1[D==1]-Y0[D==1])\n\n\n[1] 0.2027119\n\n\nClick para ver el código\n#ATU:\nmean(Y1[D==0]-Y0[D==0])\n\n\n[1] 0.1983427\n\n\nPodemos usar el \\(SDM\\) para estimar \\(ATE=ATT=ATU\\):\n\n\nClick para ver el código\nY &lt;- Y1*D+Y0*(1-D)\n\n#SDM\nmean(Y[D==1])-mean(Y[D==0])\n\n\n[1] 0.1985492\n\n\nLo mismo podemos hacer con una regresión:\n\nClick para ver el código\nlibrary(texreg)\nreg &lt;- lm(Y~D)\n\n# Reportamos estos modelos\nhtmlreg(l=list(reg))\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModel 1\n\n\n\n\n\n\n(Intercept)\n\n\n0.00\n\n\n\n\n \n\n\n(0.00)\n\n\n\n\nDTRUE\n\n\n0.20***\n\n\n\n\n \n\n\n(0.01)\n\n\n\n\nR2\n\n\n0.01\n\n\n\n\nAdj. R2\n\n\n0.01\n\n\n\n\nNum. obs.\n\n\n100000\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05\n\n\n\n\n¿Qué asumimos en esta estimación?"
  },
  {
    "objectID": "S2.html#balance-y-eficiencia",
    "href": "S2.html#balance-y-eficiencia",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Balance y eficiencia",
    "text": "Balance y eficiencia\nSi la asignación ha sido realmente aleatoria, no solo debiéramos tener \\((Y_i^0,Y_i^1)\\perp D_i\\), sino que además esperaríamos tener \\(X_i\\perp D_i\\) para cualquier variable \\(X_i\\) observada antes del programa. La independencia nos dirá que tanto los resultados potenciales como las covariables son independientes de la asignación de tratamiento: \\((Y_i^0,Y_i^1), X \\perp D_i\\)\nUna forma de verificar que la asignación ha sido realmente aleatoria, es comparar las características observadas en la línea de base entre unidades tratadas y no tratadas. El procedimiento para evaluar balance incluye:\n\nTest de medias\n\n\\[t = \\frac{\\bar{X}_T - \\bar{X}_C}{\\sqrt{\\frac{s_T^2}{n_T} + \\frac{s_C^2}{n_C}}}\\] * Camino rápido: un modelo logístico con la variable \\(D_i\\) como dependiente y todas las variables observadas como independientes.\n\nOmnibus Test: Con base en inferencia por aleatorización, se utiliza un test F para evaluar el balance general de todas las covariables conjuntamente. Esto permite verificar si el conjunto completo de covariables muestra una diferencia significativa en su balance entre los grupos: \\[F = \\frac{\\text{MSB}}{\\text{MSW}}\\]\n\nSi la distribución de \\(X_i\\) es similar en ambos grupos, podemos tomarlo como evidencia de que la aleatorización fue efectiva y por lo tanto ambos grupos son comparables tanto en variables observables como en variables no observables. Sin embargo, existe falta de balance si hay correlación entre la covariable \\(X\\) y la asignación de tratamiento \\(D\\). Esto se traduce en: \\[\\text{Cov}(X, D) \\neq 0\\]\nEn el contexto de experimentos, aunque la inferencia causal no requiere covariables, el uso de variables de control puede ser útil para:\n\nReducir la varianza en los resultados potenciales, al re-escalar la variable dependiente.\nEliminar diferencias observadas entre los grupos de tratamiento y control en análisis de regresión.\nFormar bloques para mejorar el diseño experimental.\n\nEn caso de desbalance, la regresión permite estimar el ATE bajo el control de varias covariables. La relación con el modelo contrafactual es la siguiente:\n\\[\\begin{split}Y_i & = Y_i(0)(1 - d_i) + Y_i(1)d_i\n    \\\\ & = Y_i(0) + (Y_i(1) - Y_i(0))d_i\n    \\\\ & = \\mu_{Y(0)} + [\\mu_{Y(1)} - \\mu_{Y(0)}]d_i + (Y_i(0) - \\mu_{Y(0)}) + [(Y_i(1) - \\mu_{Y(1)}) - (Y_i(0) - \\mu_{Y(0)})]d_i\n    \\\\ & = \\alpha + \\beta d_i + u_i\\end{split}\\]\nDonde:\n\n\\(\\alpha=\\mu_{Y(0)}\\)\n\\(\\beta=\\mu_{Y(1)} - \\mu_{Y(0)}\\) es el ATE\n\\(u_i=Y_i(0) - \\mu_{Y(0)}\\) si \\(d_i=0\\) o \\(u_i=Y_i(1) - \\mu_{Y(1)}\\) si \\(d_i=1\\)"
  },
  {
    "objectID": "S2.html#ejemplo-muralidharan-et-al.-2019",
    "href": "S2.html#ejemplo-muralidharan-et-al.-2019",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Ejemplo: Muralidharan et al. (2019)",
    "text": "Ejemplo: Muralidharan et al. (2019)\nMuralidharan, K., Singh, A., & Ganimian, A. J. (2019). Disrupting education? Experimental evidence on technology-aided instruction in India. American Economic Review, 109(4), 1426-1460.\n¿Puede un software de aprendizaje mejorar los resultados académicos de niños en edad escolar?\nProblema: Brechas académicas entre estudiantes que están en el mismo nivel.\n\n\n\n\n\nMindspark Cal software, desarrollado por Educational Initiatives en India:\n\nCombina videos instructivos, juegos, actividades y evaluación continua\nMaterial de alta calidad diseñado y testeado a lo largo de varios años\nContenido adaptativo, i) se adecúa al nivel del niño y ii) profundiza en áreas en las que el niño parece mantener concepciones erradas.\n\nLa pregunta cobra especial relevancia en el contexto de pandemia, en que la educación a distancia puede ser la única alternativa.\nMás allá del contexto actual, existe un debate en cuanto a si este tipo de tecnologías ayuda al aprendizaje o más bien distrae a los niños.\nDiseño experimental\n\nLa intervención consistió en sesiones de aprendizaje con el software Mindspark Cal realizadas en 3 centros Mindspark\nReclutamiento de alumnos en 5 escuelas\n619 participantes (postulantes).\nAsignación aleatoria:\n\n314 en T\n305 en C\n\nAtrición de 15% para los tratados y de 90% para los controles.\n\n¿Supuestos?\nBalance\n\n\n\n\n\nITT\n¿Por qué un ITT?\n\n\n\n\n\nITT (regresiones)\n\n\n\n\n\nITT (heterogeneidad)"
  },
  {
    "objectID": "S2.html#limitaciones-de-aleatorizar",
    "href": "S2.html#limitaciones-de-aleatorizar",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Limitaciones de aleatorizar",
    "text": "Limitaciones de aleatorizar\n\nLa asignación aleatoria de un tratamiento hace posible la identificación de efectos causales por medio de eliminar el sesgo de selección\nEsto ha llevado a que las evaluaciones experimentales o RCTs (randomized controlled trials) se consideren el estándar de oro de la evaluación de impacto\nPero la asignación aleatoria no siempre es posible:\n\nExisten restricciones éticas, legales y prácticas\nNo podemos aleatorizar los años de escolaridad que recibe un grupo de niños\nNo podemos aleatorizar el barrio en el que viven las familias\nNo podemos aleatorizar la entrega de beneficios sociales otorgados por ley, etc.\n\n\nPara saber si es ético asignar un programa en forma aleatoria, debemos responder las siguientes preguntas:\n\n¿Existen recursos disponibles para ofrecer el programa a todos los interesados?\n¿Es posible distinguir precisamente quiénes necesitan/merecen más un programa?\nA priori, ¿Cuánto sabemos acerca de la efectividad del programa?\nSi no hay suficientes recursos para ofrecer el programa a todos y, hasta cierto punto, no es posible distinguir quién necesita más el programa, entonces se puede argumentar que .orange[la asignación aleatoria es lo más justo]\nCuando sabemos muy poco acerca de la efectividad de un programa (de modo que no es evidente que T es mejor que C), la asignación aleatoria puede justificarse por los beneficios que traería .orange[aprender sobre la efectividad del programa]… incluso si los recursos alcanzaran para atender a todos (ejemplo: vacunas).\nEntonces, la aleatorización no es intrínsecamente ética o no ética. Todo depende de la situación."
  },
  {
    "objectID": "S2.html#experimento-ideal",
    "href": "S2.html#experimento-ideal",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Experimento ideal",
    "text": "Experimento ideal\nIncluso si un experimento no es factible, Angrist & Pischke (2009) recomiendan pensar en el “experimento ideal” a la hora de diseñar una evaluación de impacto.\n\nMétodos no experimentales de identificación causal buscan situaciones en las que la asignación del tratamiento sea “as-good-as-random”.\nAlgunos le llaman a estos métodos: métodos cuasi-aleatorios/cusi-experimentales.\n\nVeremos algunos la próxima sesión…"
  },
  {
    "objectID": "S2.html#extra-poder-estadístico-en-un-experimento",
    "href": "S2.html#extra-poder-estadístico-en-un-experimento",
    "title": "Sesión 2: Diseños experimentales",
    "section": "Extra: Poder estadístico en un experimento",
    "text": "Extra: Poder estadístico en un experimento\nProximamente…"
  },
  {
    "objectID": "S1.html",
    "href": "S1.html",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "",
    "text": "Podemos entender la inferencia causal como el interés por estimar el efecto de los acontencimientos y las decisiones sobre un resultado de interés determinado.\nAlgunos ejemplos:\n\n\n\n\n\nZubizarreta, J. R., Cerdá, M., & Rosenbaum, P. R. (2013). Effect of the 2010 Chilean earthquake on posttraumatic stress: reducing sensitivity to unmeasured bias through study design. Epidemiology, 24(1), 79-87.\n\n\n\n\n\nTorche, F. (2011). The effect of maternal stress on birth outcomes: exploiting a natural experiment. Demography, 48, 1473-1491.\n\n\n\n\n\nMuralidharan, K., Singh, A., & Ganimian, A. J. (2019). Disrupting education? Experimental evidence on technology-aided instruction in India. American Economic Review, 109(4), 1426-1460.\nFundamental\n\nDatos: ¿Cuál es la estrategia de identificación?\nSupuestos: ¿Cuáles son los supuestos que sustentan la causalidad en un estudio?\n\nSin embargo, tendremos algunos inconvenientes…"
  },
  {
    "objectID": "S1.html#qué-es-la-inferencia-causal",
    "href": "S1.html#qué-es-la-inferencia-causal",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "",
    "text": "Podemos entender la inferencia causal como el interés por estimar el efecto de los acontencimientos y las decisiones sobre un resultado de interés determinado.\nAlgunos ejemplos:\n\n\n\n\n\nZubizarreta, J. R., Cerdá, M., & Rosenbaum, P. R. (2013). Effect of the 2010 Chilean earthquake on posttraumatic stress: reducing sensitivity to unmeasured bias through study design. Epidemiology, 24(1), 79-87.\n\n\n\n\n\nTorche, F. (2011). The effect of maternal stress on birth outcomes: exploiting a natural experiment. Demography, 48, 1473-1491.\n\n\n\n\n\nMuralidharan, K., Singh, A., & Ganimian, A. J. (2019). Disrupting education? Experimental evidence on technology-aided instruction in India. American Economic Review, 109(4), 1426-1460.\nFundamental\n\nDatos: ¿Cuál es la estrategia de identificación?\nSupuestos: ¿Cuáles son los supuestos que sustentan la causalidad en un estudio?\n\nSin embargo, tendremos algunos inconvenientes…"
  },
  {
    "objectID": "S1.html#problema-fundamental-de-la-inferencia-causal",
    "href": "S1.html#problema-fundamental-de-la-inferencia-causal",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "Problema fundamental de la inferencia causal",
    "text": "Problema fundamental de la inferencia causal\nConsidere una población de \\(i\\) unidades potencialmente expuestas a un tratamiento (causa) o control. La variable \\(D_i\\) nos indicará si la unidad \\(i\\) fue tratada (\\(D_i=t\\)) o no tratada, o sea control, (\\(D_i=c\\)).\nNos interesa evaluar el efecto sobre una variable de respuesta observada que denotaremos como \\(Y_i\\) con dos respuestas potenciales:\n\n\\(Y_i(t)\\) si la unidad fue tratada\n\\(Y_i(c)\\) en caso contrario\n\nDado que \\(Y_i\\) mide el efecto de la causa, entonces, los valores de \\(Y_i\\) son posteriores a la exposición del tratamiento.\nA su vez, denotamos que el modelo causal del tratamiento en una unidad \\(i\\) puede ser expresado como:\n\\[\\delta_i=Y_i(t)-Y_i(c)\\]\nLo interesante del modelo Neyman-Rubin es que el valor de \\(D_i\\) para cada unidad \\(i\\) podría haber sido distinto. Este es el problema.\n\\[Y_i=D_iY_i(t)-(1-D_i)Y_i(c)\\] Donde \\(D_i=1\\) si la persona fue tratada y \\(D_i=0\\) en caso contrario, entonces:\n\\[\\delta_i=(1)Y_i(t)-(1-0)Y_i(c)=Y_i(t)-Y_i(c)\\]\n\n\n\n\n\n\nProblema fundamental de la inferencia causal\n\n\n\nLa imposibilidad de observar una variable de respuesta \\(Y_i\\) en la misma unidad y al mismo tiempo para dos condiciones diferentes: \\(Y_i(t)\\) y \\(Y_i(c)\\).\n\n\n \nGraficamente:\n\n\n\n\n\nEste es problema de missing data para los tratados solo conocemos \\(Y_i(t)\\) y para los controles solo conocemos \\(Y_i(c)\\).\n¿Qué se puede hacer?"
  },
  {
    "objectID": "S1.html#average-treatment-effect-ate",
    "href": "S1.html#average-treatment-effect-ate",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "Average Treatment Effect (ATE)",
    "text": "Average Treatment Effect (ATE)\nVeamos los siguientes resultados potenciales:\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{split}ATE & = \\frac{1}{10}\\cdot(6-1+4-1+2 \\\\& \\quad +9-9-1-4+1) \\\\ & = \\frac{6}{10}=0.6\\end{split}\\]\nPodemos usar la población \\(U\\) mediante un efecto causal promedio (ATE) como el valor esperado de la diferencia \\(Y_i(t)-Y_i(c)\\) en los \\(i\\)’s de \\(U\\):\n\n\n\n\n\n\n\n\n\n\n\n\nLo que está en naranjo no es observable, por lo que no es posible calcular el ATE directamente, entonces:\n\n\\[\n\\begin{align}\n   ATE & = E[\\delta_i] \\nonumber      \\\\\n       & = E[Y_i(t) - Y_i(t)] \\nonumber \\\\\n       & = E[Y_i(t)] - E[Y_i(c)]        \n\\end{align}\n\\]  Adaptado de Broockman, D. E., Kalla, J. L., & Sekhon, J. S. (2017). The design of field experiments with survey outcomes: A framework for selecting more efficient, robust, and ethical designs. Political Analysis, 25(4), 435-464."
  },
  {
    "objectID": "S1.html#supuestos",
    "href": "S1.html#supuestos",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "Supuestos",
    "text": "Supuestos\nSi \\(Y_{i}(D_i)\\) es una variable de respuesta observada cuyo valor puede ser \\(D_i=1\\) para \\(Y_{i}(t)\\) o \\(D_i=0\\) para \\(Y_{i}(c)\\), entonces:\nIndependencia: la asignación al tratamiento es independiente de la variable resultado para tratados (\\(Y_{i}(t)\\)) y controles (\\(Y_{i}(c)\\)), y de cualquier otra variable en la población, formalmente queda expresado de la siguiente manera: \\[(Y_{i}(t), Y_{i}(c)) \\perp D_{i}\\] En otras palabras:\n\n\\(E[Y_i(t)]=E[Y_i(t)|D_i=1]\\)\n\\(E[Y_i(c)]=E[Y_i(c)|D_i=0]\\)\n\\(ATE=E[Y_i(1)|D_i=1] - E[Y_i(0)|D_i=0]\\)\n\nLos términos son equivalentes e intercambiables:\n\nTratados: \\(E[Y_i(1)|D_i=1] = E[Y_i(1)|D_i=0] = E[Y_i(1)]\\)\nControles: \\(E[Y_i(0)|D_i=0] = E[Y_i(0)|D_i=0] = E[Y_i(0)]\\)\n\nEn consecuencia la asignación al grupo de tratamiento o control no incide sobre el valor esperado. Por lo tanto, la asignación aleatoria es condición de posibilidad de la independencia y se deduce que, en los promedios, la única diferencia entre \\((D_{t}\\) y \\((D_{c}\\) corresponde a que un grupo fue tratado y el otro no. En definitiva, se puede estimar el \\(ATE\\) como el efecto promedio del medicaid para el grupo tratamiento y en el grupo de control:\n\\[\\frac{1}{N}\\sum_{i=1}^{N} Y_{i}(t) - \\frac{1}{N}\\sum_{i=1}^{N} Y_{i}(c)\\]\nRestricción de exclusión: los resultados del experimento dependen únicamente de la exposición al tratamiento \\((D_{i}=1)\\) y no de la asignación entre grupo de tratamiento y control. En términos formales nos permite identificar el efecto causal. En definitiva se espera que todos los individuos asignados al tratamiento sean expuestos al estímulo, a su vez, los asignados al grupo de control no son expuestos al estímulo: \\[Y_{i}(1,d) = Y_{i}(0,d)\\]\nStable-unit-treatment assumption (SUTVA): no hay interferencia (spillovers) en la respuesta al tratamiento de un individuo en comparación a otro. En otras palabras, si la observación \\(i\\) se expone al tratamiento \\(t\\), el valor de la variable resultado \\(Y\\) se mantendrá igual sin importar el tipo de asignación ni el tipo de tratamiento que reciban las otras observaciones \\(i\\) (sería problemático que la asignación del seguro a un individuo afectara el resultado de salud en otro individuo). Esto nos garantiza de que solo existan dos respuestas ante la condición de tratamiento (asignación), independiente de las otras unidades. Por lo tanto, podemos estimar la causalidad como al diferencia en la variable resultado para el grupo de tratamiento y el grupo de control.\n\n\n\n\n\nAdaptado de Broockman, D. E., Kalla, J. L., & Sekhon, J. S. (2017). The design of field experiments with survey outcomes: A framework for selecting more efficient, robust, and ethical designs. Political Analysis, 25(4), 435-464.\nAlgunos ejemplos:\n\nSalud pública: efecto rebaño.\nEducación: estudiantes pueden compartir su conocimiento con amigos.\nCriminología: la presencia policial puede desplazar la criminalidad a otras áreas."
  },
  {
    "objectID": "S1.html#la-idea-del-contrafactual",
    "href": "S1.html#la-idea-del-contrafactual",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "La idea del contrafactual",
    "text": "La idea del contrafactual\nPensemos dos escenarios, ¿podemos identificar el efecto?\n\nComparaciones antes-después: cotejan los resultados del mismo grupo antes y después de una intervención.\nComparaciones de participantes versus no participantes: comparan los resultados de un grupo que elige participar de la intervención versus otro grupo que elige no participar."
  },
  {
    "objectID": "S1.html#correlación-vs-causalidad",
    "href": "S1.html#correlación-vs-causalidad",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "Correlación vs causalidad",
    "text": "Correlación vs causalidad\nEn muchos estudios e investigaciones, es fácil observar una correlación entre dos variables, como la acción del hombre dentro del vehículo y el movimiento de este, pero eso no significa que una variable cause la otra. La causalidad implica un mecanismo claro que conecta las variables de manera que una provoque la otra, como las personas empujando el vehículo desde fuera.\n\n\n\n\n\nLa pregunta de fondo es ¿la correlación observada es causal?\nCausalidad \\(\\neq\\) Asociación:\n\\(E[Y_i(1)] - E[Y_i(0)] \\neq E[Y_i(1) | D_i = 1] - E[Y_i(0) | D_i = 0]\\)\nDos condiciones necesarias:\n\n\\(E[Y_i(1)|D_i=1]=E[Y_i(1)|D_i=0]=E[Y_i(1)]\\)\n\\(E[Y_i(0)|D_i=0]=E[Y_i(0)|D_i=1]=E[Y_i(0)]\\)\n\nSi las condiciones 1 y 2 se cumplen entonces: Causalidad \\(=\\) Asociación:\n\n\n\n\n\nPensemos en algunas relaciones:\n\n¿El cinturón de seguridad (X) reduce mortalidad por accidentes (Y)?\n¿La contaminación industrial (X) aumenta la temperatura del planeta (Y)?\n¿Un mayor nivel educativo del padre (X) aumenta el nivel educativo del hijo?\n¿Venir a clases (X) mejora mi nota final (Y)?\n\nEl concepto clave para responder estas preguntas sobre causalidad es el de contrafactual o contrafáctico ¿Qué hubiese pasado en ausencia del tratamiento? El escenario ideal es poder comparar el resultado cuando ocurre y cuando no ocurre."
  },
  {
    "objectID": "S1.html#aproximación-al-ate-vía-regresión-lineal",
    "href": "S1.html#aproximación-al-ate-vía-regresión-lineal",
    "title": "Sesión 1: Inferencia causal en ciencias sociales",
    "section": "Aproximación al ATE vía regresión lineal",
    "text": "Aproximación al ATE vía regresión lineal\n\nAproximación clásica\nPodemos obtener una aproximación directa a partir de datos:\n\n\nClick para ver el código\n# Librerías de trabajo\nlibrary(dplyr) # Manipulación \nlibrary(tidyr) # Manipulación \nlibrary(broom) # Para manipular objetos\nlibrary(Matrix)\nlibrary(AER) # Contiene los datos \nlibrary(texreg) # Contiene los datos \n\n# Extraemos los datos \ndata(STAR)\nglimpse(STAR)\n\n\nRows: 11,598\nColumns: 47\n$ gender      &lt;fct&gt; female, female, female, male, male, male, male, female, ma…\n$ ethnicity   &lt;fct&gt; afam, cauc, afam, cauc, afam, cauc, afam, cauc, cauc, cauc…\n$ birth       &lt;yearqtr&gt; 1979 Q3, 1980 Q1, 1979 Q4, 1979 Q4, 1980 Q1, 1979 Q3, …\n$ stark       &lt;fct&gt; NA, small, small, NA, regular+aide, NA, NA, NA, NA, NA, re…\n$ star1       &lt;fct&gt; NA, small, small, NA, NA, NA, NA, regular+aide, regular, r…\n$ star2       &lt;fct&gt; NA, small, regular+aide, NA, NA, regular, NA, regular+aide…\n$ star3       &lt;fct&gt; regular, small, regular+aide, small, NA, regular, regular+…\n$ readk       &lt;int&gt; NA, 447, 450, NA, 439, NA, NA, NA, NA, NA, 448, 447, 431, …\n$ read1       &lt;int&gt; NA, 507, 579, NA, NA, NA, NA, 475, NA, 651, 651, 533, 558,…\n$ read2       &lt;int&gt; NA, 568, 588, NA, NA, NA, NA, 573, NA, 596, 614, 608, 608,…\n$ read3       &lt;int&gt; 580, 587, 644, 686, NA, 644, NA, 599, NA, 626, 641, 665, 5…\n$ mathk       &lt;int&gt; NA, 473, 536, NA, 463, NA, NA, NA, NA, NA, 559, 489, 454, …\n$ math1       &lt;int&gt; NA, 538, 592, NA, NA, NA, NA, 512, NA, 532, 584, 545, 553,…\n$ math2       &lt;int&gt; NA, 579, 579, NA, NA, NA, NA, 550, NA, 590, 639, 603, 579,…\n$ math3       &lt;int&gt; 564, 593, 639, 667, NA, 648, NA, 583, NA, 618, 684, 648, 5…\n$ lunchk      &lt;fct&gt; NA, non-free, non-free, NA, free, NA, NA, NA, NA, NA, non-…\n$ lunch1      &lt;fct&gt; NA, free, NA, NA, NA, NA, NA, non-free, non-free, non-free…\n$ lunch2      &lt;fct&gt; NA, non-free, non-free, NA, NA, non-free, NA, non-free, no…\n$ lunch3      &lt;fct&gt; free, free, non-free, non-free, NA, non-free, free, non-fr…\n$ schoolk     &lt;fct&gt; NA, rural, suburban, NA, inner-city, NA, NA, NA, NA, NA, r…\n$ school1     &lt;fct&gt; NA, rural, suburban, NA, NA, NA, NA, rural, rural, rural, …\n$ school2     &lt;fct&gt; NA, rural, suburban, NA, NA, rural, NA, rural, rural, rura…\n$ school3     &lt;fct&gt; suburban, rural, suburban, rural, NA, rural, inner-city, r…\n$ degreek     &lt;fct&gt; NA, bachelor, bachelor, NA, bachelor, NA, NA, NA, NA, NA, …\n$ degree1     &lt;fct&gt; NA, bachelor, master, NA, NA, NA, NA, master, master, bach…\n$ degree2     &lt;fct&gt; NA, bachelor, bachelor, NA, NA, bachelor, NA, master, bach…\n$ degree3     &lt;fct&gt; bachelor, bachelor, bachelor, bachelor, NA, bachelor, bach…\n$ ladderk     &lt;fct&gt; NA, level1, level1, NA, probation, NA, NA, NA, NA, NA, lev…\n$ ladder1     &lt;fct&gt; NA, level1, probation, NA, NA, NA, NA, apprentice, level1,…\n$ ladder2     &lt;fct&gt; NA, apprentice, level1, NA, NA, notladder, NA, level1, lev…\n$ ladder3     &lt;fct&gt; level1, apprentice, level1, level1, NA, level1, notladder,…\n$ experiencek &lt;int&gt; NA, 7, 21, NA, 0, NA, NA, NA, NA, NA, 16, 5, 8, 17, NA, NA…\n$ experience1 &lt;int&gt; NA, 7, 32, NA, NA, NA, NA, 8, 13, 7, 11, 15, 0, 5, NA, 17,…\n$ experience2 &lt;int&gt; NA, 3, 4, NA, NA, 13, NA, 13, 6, 8, 31, 14, 9, NA, 4, 28, …\n$ experience3 &lt;int&gt; 30, 1, 4, 10, NA, 15, 17, 23, 8, 8, 7, 14, 8, NA, 19, 13, …\n$ tethnicityk &lt;fct&gt; NA, cauc, cauc, NA, cauc, NA, NA, NA, NA, NA, cauc, cauc, …\n$ tethnicity1 &lt;fct&gt; NA, cauc, afam, NA, NA, NA, NA, cauc, cauc, cauc, cauc, ca…\n$ tethnicity2 &lt;fct&gt; NA, cauc, afam, NA, NA, cauc, NA, afam, cauc, cauc, cauc, …\n$ tethnicity3 &lt;fct&gt; cauc, cauc, cauc, cauc, NA, cauc, afam, cauc, cauc, cauc, …\n$ systemk     &lt;fct&gt; NA, 30, 11, NA, 11, NA, NA, NA, NA, NA, 35, 41, 4, 11, NA,…\n$ system1     &lt;fct&gt; NA, 30, 11, NA, NA, NA, NA, 4, 40, 21, 35, 41, 4, 11, NA, …\n$ system2     &lt;fct&gt; NA, 30, 11, NA, NA, 6, NA, 4, 40, 21, 35, 41, 4, NA, 17, 2…\n$ system3     &lt;fct&gt; 22, 30, 11, 6, NA, 6, 11, 4, 40, 21, 35, 41, 4, NA, 17, 20…\n$ schoolidk   &lt;fct&gt; NA, 63, 20, NA, 19, NA, NA, NA, NA, NA, 69, 79, 5, 16, NA,…\n$ schoolid1   &lt;fct&gt; NA, 63, 20, NA, NA, NA, NA, 5, 77, 50, 69, 79, 5, 16, NA, …\n$ schoolid2   &lt;fct&gt; NA, 63, 20, NA, NA, 8, NA, 5, 77, 50, 69, 79, 5, NA, 41, 4…\n$ schoolid3   &lt;fct&gt; 54, 63, 20, 8, NA, 8, 31, 5, 77, 50, 69, 79, 5, NA, 41, 48…\n\n\nEl conjunto de datos del Project STAR (Student/Teacher Achievement Ratio) proviene de un estudio longitudinal de cuatro años financiado por la Asamblea General de Tennessee y llevado a cabo a fines de la década de 1980 por el Departamento de Educación del Estado. Este estudio incluyó a más de 5,000 estudiantes de 79 escuelas, asignados aleatoriamente a una de tres intervenciones: clases pequeñas (13 a 17 estudiantes por maestro), clases regulares (22 a 25 estudiantes por maestro), y clases regulares con asistente (22 a 25 estudiantes con un asistente de maestro a tiempo completo). Los docentes también fueron asignados aleatoriamente a los grupos que enseñarían. Las intervenciones comenzaron cuando los estudiantes ingresaron al jardín de infancia y continuaron hasta el tercer grado. Stock y Watson (2007) obtuvieron este conjunto de datos del sitio web del Project STAR.\nVamos a trabajar con una versión sencilla de estos datos:\n\n\nClick para ver el código\n# Procesamos los datos\nSTAR &lt;- STAR %&gt;% \n  tidyr::drop_na(readk, mathk) %&gt;% \n  mutate(str=if_else(stark==\"small\", 1, 0)) %&gt;% \n  rowwise() %&gt;% \n  mutate(tscorek=(readk + mathk)) %&gt;% \n  select(str, tscorek, readk, mathk)\n\n# Veamos los datos\nglimpse(STAR)\n\n\nRows: 5,786\nColumns: 4\nRowwise: \n$ str     &lt;dbl&gt; 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,…\n$ tscorek &lt;int&gt; 920, 986, 902, 1007, 936, 885, 818, 951, 917, 983, 903, 905, 1…\n$ readk   &lt;int&gt; 447, 450, 439, 448, 447, 431, 395, 451, 478, 455, 430, 437, 47…\n$ mathk   &lt;int&gt; 473, 536, 463, 559, 489, 454, 423, 500, 439, 528, 473, 468, 55…\n\n\nSi consideramos la definición:\n\\[\n\\begin{align}\n   ATE & = E[\\delta_i] \\nonumber      \\\\\n       & = E[Y_i(t) - Y_i(t)] \\nonumber \\\\\n       & = E[Y_i(t)] - E[Y_i(c)]        \n\\end{align}\n\\] Podemos programar esto:\n\n\nClick para ver el código\n# Definimos la función \nestimador_ATE &lt;- function(data, tratamiento, variable_resultado) {\n  # Calcular la media del resultado para el grupo tratado\n  Yt &lt;- mean(data[[variable_resultado]][data[[tratamiento]] == 1], na.rm = TRUE)\n  \n  # Calcular la media del resultado para el grupo de control\n  Yc &lt;- mean(data[[variable_resultado]][data[[tratamiento]] == 0], na.rm = TRUE)\n  \n  # Calcular el ATE\n  ATE &lt;- Yt - Yc\n  \n  # Devolver el ATE\n  return(ATE)\n}\n\n\n\n\nClick para ver el código\n# Aplicamos los datos\nestimador_ATE(STAR, tratamiento = \"str\", variable_resultado = \"tscorek\")\n\n\n[1] 13.74055\n\n\nClick para ver el código\nestimador_ATE(STAR, tratamiento = \"str\", variable_resultado = \"readk\")\n\n\n[1] 5.463098\n\n\nClick para ver el código\nestimador_ATE(STAR, tratamiento = \"str\", variable_resultado = \"mathk\")\n\n\n[1] 8.277455\n\n\nUna alternativa a esto:\n\n\nClick para ver el código\nSTAR %&gt;%\n  t.test(tscorek ~ str, data = .) %&gt;%\n  tidy()\n\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic  p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1    -13.7      918.      932.     -6.38 2.07e-10     3129.    -18.0     -9.52\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\n\n\nAproximación vía regresión\nPodemos aproximarnos al ATE mediante un modelo de regresión lineal:\n\\[\n\\begin{align}\n   Y_i & = Y_i(0)(1 - d_i) + Y_i(1)d_i \\\\\n       & = Y_i(0) + (Y_i(1) - Y_i(0))d_i \\\\\n       & = \\mu_{Y(0)} + [\\mu_{Y(1)} - \\mu_{Y(0)}]d_i + Y_i(0) - \\mu_{Y(0)} + [(\\mu_{Y(1)} - \\mu_{Y(0)}) - (Y_i(0) - \\mu_{Y(0)})]d_i     \\\\\n       & = \\alpha + \\beta d_i + u_i\n\\end{align}\n\\]\nDonde:\n\n\\((\\alpha)\\) es el intercepto y es igual a \\((\\mu_{Y(0)})\\).\n\\((\\beta)\\) es \\((\\mu_{Y(1)} - \\mu_{Y(0)})\\), es decir, ATE.\n\\((u_i = Y_i(0) - \\mu_{Y(0)}) si (d_i = 0)\\) o \\((u_i = Y_i(1) - \\mu_{Y(1)})\\) si \\((d_i = 1)\\).\n\nPor ejemplo:\n\nClick para ver el código\n# Definimos y estimamos el modelo \nmodelo1 &lt;- lm(tscorek ~ str, data = STAR)\nmodelo2 &lt;- lm(readk ~ str, data = STAR)\nmodelo3 &lt;- lm(mathk ~ str, data = STAR)\n\n# Reportamos estos modelos\nhtmlreg(l=list(modelo1, modelo2, modelo3))\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModel 1\n\n\nModel 2\n\n\nModel 3\n\n\n\n\n\n\n(Intercept)\n\n\n918.20***\n\n\n435.09***\n\n\n483.11***\n\n\n\n\n \n\n\n(1.15)\n\n\n(0.50)\n\n\n(0.75)\n\n\n\n\nstr\n\n\n13.74***\n\n\n5.46***\n\n\n8.28***\n\n\n\n\n \n\n\n(2.11)\n\n\n(0.91)\n\n\n(1.36)\n\n\n\n\nR2\n\n\n0.01\n\n\n0.01\n\n\n0.01\n\n\n\n\nAdj. R2\n\n\n0.01\n\n\n0.01\n\n\n0.01\n\n\n\n\nNum. obs.\n\n\n5786\n\n\n5786\n\n\n5786\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05\n\n\n\n\n¿Cómo interpretamos estos modelos? ¿Qué limitaciones pueden presentar?"
  },
  {
    "objectID": "S3.html",
    "href": "S3.html",
    "title": "Sesión 3: Técnicas cuasi-experimentales",
    "section": "",
    "text": "Proximamente…"
  }
]